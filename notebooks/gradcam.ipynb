{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from utils import *\n",
    "from GradCAM.modeltrain import train_model, select_model, eval_model\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from torchcam.utils import overlay_mask\n",
    "\n",
    "from PIL import Image\n",
    "# from torchcam.methods import GradCAMpp, GradCAM\n",
    "from torchvision.io.image import read_image\n",
    "from torchvision.transforms.functional import normalize, resize, to_pil_image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, preprocess_image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"cifar100\"\n",
    "datasetpath = f\"../datasets/{dataset_name}\"\n",
    "saliencymappath = f\"../datasets/{dataset_name}_saliency_maps\"\n",
    "n_classes = int(dataset_name[5:])\n",
    "model_name = \"vgg16\"\n",
    "savepath = f\"../GradCAM/saved_models/{dataset_name}\"\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_models = 4\n",
    "batch_size = 256\n",
    "learning_rate = 0.001\n",
    "epochs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Load CIFAR-10 dataset\n",
    "if dataset_name==\"cifar10\":\n",
    "    train_dataset = datasets.CIFAR10(root=datasetpath, train=True, transform=transform, download=True)\n",
    "    test_dataset = datasets.CIFAR10(root=datasetpath, train=False, transform=transform, download=True)\n",
    "elif dataset_name==\"cifar100\":\n",
    "    train_dataset = datasets.CIFAR100(root=datasetpath, train=True, transform=transform, download=True)\n",
    "    test_dataset = datasets.CIFAR100(root=datasetpath, train=False, transform=transform, download=True)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 -> Training Accuracy: 0.1060, Validation Accuracy: 0.2899\n",
      "New best model saved with accuracy: 0.2899\n",
      "Epoch [1/32], Loss: 4.0375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 -> Training Accuracy: 0.3851, Validation Accuracy: 0.4295\n",
      "New best model saved with accuracy: 0.4295\n",
      "Epoch [2/32], Loss: 2.3186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 -> Training Accuracy: 0.4783, Validation Accuracy: 0.4735\n",
      "New best model saved with accuracy: 0.4735\n",
      "Epoch [3/32], Loss: 1.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 -> Training Accuracy: 0.5292, Validation Accuracy: 0.5037\n",
      "New best model saved with accuracy: 0.5037\n",
      "Epoch [4/32], Loss: 1.6580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 -> Training Accuracy: 0.5685, Validation Accuracy: 0.5231\n",
      "New best model saved with accuracy: 0.5231\n",
      "Epoch [5/32], Loss: 1.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 -> Training Accuracy: 0.6024, Validation Accuracy: 0.5329\n",
      "New best model saved with accuracy: 0.5329\n",
      "Epoch [6/32], Loss: 1.3808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 -> Training Accuracy: 0.6293, Validation Accuracy: 0.5439\n",
      "New best model saved with accuracy: 0.5439\n",
      "Epoch [7/32], Loss: 1.2730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 -> Training Accuracy: 0.6536, Validation Accuracy: 0.5508\n",
      "New best model saved with accuracy: 0.5508\n",
      "Epoch [8/32], Loss: 1.1781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 -> Training Accuracy: 0.6799, Validation Accuracy: 0.5606\n",
      "New best model saved with accuracy: 0.5606\n",
      "Epoch [9/32], Loss: 1.0898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 -> Training Accuracy: 0.7005, Validation Accuracy: 0.5630\n",
      "New best model saved with accuracy: 0.5630\n",
      "Epoch [10/32], Loss: 1.0078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 -> Training Accuracy: 0.7242, Validation Accuracy: 0.5611\n",
      "Epoch [11/32], Loss: 0.9266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 -> Training Accuracy: 0.7442, Validation Accuracy: 0.5660\n",
      "New best model saved with accuracy: 0.5660\n",
      "Epoch [12/32], Loss: 0.8487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 -> Training Accuracy: 0.7676, Validation Accuracy: 0.5700\n",
      "New best model saved with accuracy: 0.5700\n",
      "Epoch [13/32], Loss: 0.7745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 -> Training Accuracy: 0.7879, Validation Accuracy: 0.5681\n",
      "Epoch [14/32], Loss: 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 -> Training Accuracy: 0.8103, Validation Accuracy: 0.5689\n",
      "Epoch [15/32], Loss: 0.6297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 -> Training Accuracy: 0.8291, Validation Accuracy: 0.5738\n",
      "New best model saved with accuracy: 0.5738\n",
      "Epoch [16/32], Loss: 0.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 -> Training Accuracy: 0.8507, Validation Accuracy: 0.5701\n",
      "Epoch [17/32], Loss: 0.4970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 -> Training Accuracy: 0.8710, Validation Accuracy: 0.5688\n",
      "Epoch [18/32], Loss: 0.4314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 -> Training Accuracy: 0.8899, Validation Accuracy: 0.5698\n",
      "Epoch [19/32], Loss: 0.3721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 -> Training Accuracy: 0.9066, Validation Accuracy: 0.5630\n",
      "Epoch [20/32], Loss: 0.3161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 -> Training Accuracy: 0.9252, Validation Accuracy: 0.5649\n",
      "Epoch [21/32], Loss: 0.2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 -> Training Accuracy: 0.9383, Validation Accuracy: 0.5681\n",
      "Epoch [22/32], Loss: 0.2171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 -> Training Accuracy: 0.9504, Validation Accuracy: 0.5676\n",
      "Epoch [23/32], Loss: 0.1768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 -> Training Accuracy: 0.9636, Validation Accuracy: 0.5710\n",
      "Epoch [24/32], Loss: 0.1372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 -> Training Accuracy: 0.9723, Validation Accuracy: 0.5685\n",
      "Epoch [25/32], Loss: 0.1101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 -> Training Accuracy: 0.9812, Validation Accuracy: 0.5718\n",
      "Epoch [26/32], Loss: 0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 -> Training Accuracy: 0.9869, Validation Accuracy: 0.5724\n",
      "Epoch [27/32], Loss: 0.0609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 -> Training Accuracy: 0.9913, Validation Accuracy: 0.5725\n",
      "Epoch [28/32], Loss: 0.0474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 -> Training Accuracy: 0.9944, Validation Accuracy: 0.5689\n",
      "Epoch [29/32], Loss: 0.0344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 -> Training Accuracy: 0.9947, Validation Accuracy: 0.5672\n",
      "Epoch [30/32], Loss: 0.0302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 -> Training Accuracy: 0.9965, Validation Accuracy: 0.5758\n",
      "New best model saved with accuracy: 0.5758\n",
      "Epoch [31/32], Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 -> Training Accuracy: 0.9975, Validation Accuracy: 0.5777\n",
      "New best model saved with accuracy: 0.5777\n",
      "Epoch [32/32], Loss: 0.0180\n"
     ]
    }
   ],
   "source": [
    "model = select_model(model_name, n_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, momentum=0.6, weight_decay=5e-4)\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "modelpath = os.path.join(savepath,model_name+\".pth\")\n",
    "train_model(model, train_loader, test_loader, optimizer, device, modelpath, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAD-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if dataset_name==\"cifar10\":\n",
    "    test_dataset = datasets.CIFAR10(root=datasetpath, train=False, download=True, transform=transform)\n",
    "elif dataset_name==\"cifar100\":\n",
    "    test_dataset = datasets.CIFAR100(root=datasetpath, train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5777, 0.056762674176692965)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = select_model(model_name, n_classes)\n",
    "model.load_state_dict(torch.load(os.path.join(savepath, model_name+\".pth\")))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "eval_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "if dataset_name==\"cifar10\":\n",
    "    train = datasets.CIFAR10(root=datasetpath, train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR10(root=datasetpath, train=False, download=True, transform=transform)\n",
    "elif dataset_name==\"cifar100\":\n",
    "    train = datasets.CIFAR100(root=datasetpath, train=True, download=True, transform=transform)\n",
    "    test = datasets.CIFAR100(root=datasetpath, train=False, download=True, transform=transform)\n",
    "full = torch.utils.data.ConcatDataset([train, test])\n",
    "data_loader = DataLoader(full, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(saliencymappath, exist_ok=True)\n",
    "for class_idx in range(n_classes):\n",
    "    os.makedirs(os.path.join(saliencymappath, str(class_idx)), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0/60000 images.\n",
      "Processed 1000/60000 images.\n",
      "Processed 2000/60000 images.\n",
      "Processed 3000/60000 images.\n",
      "Processed 4000/60000 images.\n",
      "Processed 5000/60000 images.\n",
      "Processed 6000/60000 images.\n",
      "Processed 7000/60000 images.\n",
      "Processed 8000/60000 images.\n",
      "Processed 9000/60000 images.\n",
      "Processed 10000/60000 images.\n",
      "Processed 11000/60000 images.\n",
      "Processed 12000/60000 images.\n",
      "Processed 13000/60000 images.\n",
      "Processed 14000/60000 images.\n",
      "Processed 15000/60000 images.\n",
      "Processed 16000/60000 images.\n",
      "Processed 17000/60000 images.\n",
      "Processed 18000/60000 images.\n",
      "Processed 19000/60000 images.\n",
      "Processed 20000/60000 images.\n",
      "Processed 21000/60000 images.\n",
      "Processed 22000/60000 images.\n",
      "Processed 23000/60000 images.\n",
      "Processed 24000/60000 images.\n",
      "Processed 25000/60000 images.\n",
      "Processed 26000/60000 images.\n",
      "Processed 27000/60000 images.\n",
      "Processed 28000/60000 images.\n",
      "Processed 29000/60000 images.\n",
      "Processed 30000/60000 images.\n",
      "Processed 31000/60000 images.\n",
      "Processed 32000/60000 images.\n",
      "Processed 33000/60000 images.\n",
      "Processed 34000/60000 images.\n",
      "Processed 35000/60000 images.\n",
      "Processed 36000/60000 images.\n",
      "Processed 37000/60000 images.\n",
      "Processed 38000/60000 images.\n",
      "Processed 39000/60000 images.\n",
      "Processed 40000/60000 images.\n",
      "Processed 41000/60000 images.\n",
      "Processed 42000/60000 images.\n",
      "Processed 43000/60000 images.\n",
      "Processed 44000/60000 images.\n",
      "Processed 45000/60000 images.\n",
      "Processed 46000/60000 images.\n",
      "Processed 47000/60000 images.\n",
      "Processed 48000/60000 images.\n",
      "Processed 49000/60000 images.\n",
      "Processed 50000/60000 images.\n",
      "Processed 51000/60000 images.\n",
      "Processed 52000/60000 images.\n",
      "Processed 53000/60000 images.\n",
      "Processed 54000/60000 images.\n",
      "Processed 55000/60000 images.\n",
      "Processed 56000/60000 images.\n",
      "Processed 57000/60000 images.\n",
      "Processed 58000/60000 images.\n",
      "Processed 59000/60000 images.\n",
      "Saliency maps and metadata saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# JSON Metadata File\n",
    "metadata = []\n",
    "cam = GradCAM(model=model, target_layers=[model.features[-1]])\n",
    "\n",
    "# Step 4: Generate and Save Saliency Maps\n",
    "for i, (images, labels) in enumerate(data_loader):\n",
    "    images = images.to(device)\n",
    "    label = labels.to(device)\n",
    "    # Get Saliency Map\n",
    "    targets = [ClassifierOutputTarget(label)]\n",
    "    grayscale_cam = cam(input_tensor=images, targets=targets)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    \n",
    "    file_path = os.path.join(saliencymappath, str(label.item()), f\"saliency_map_{i}.npy\")\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)  # Ensure the directory exists\n",
    "    np.save(file_path, grayscale_cam)  # Save the saliency map as a .npy file\n",
    "    \n",
    "    # Append metadata (index, label, and file path)\n",
    "    metadata.append({\"index\": i, \"label\": str(label.item()), \"file_path\": file_path})\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processed {i}/{len(full)} images.\")\n",
    "\n",
    "# Save Metadata as JSON\n",
    "with open(os.path.join(saliencymappath, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"Saliency maps and metadata saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Overlay CAM on Image\n",
    "    # original_image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "    # original_image = (original_image - original_image.min()) / (original_image.max() - original_image.min())\n",
    "    # cam_image = show_cam_on_image(original_image, grayscale_cam, use_rgb=True)\n",
    "    \n",
    "    # Save Saliency Map\n",
    "    # file_path = os.path.join(saliencymappath, str(label.item()), f\"saliency_map_{i}.png\")\n",
    "    # # cam_image1 = Image.fromarray(cam_image)\n",
    "    # # cam_image.save(file_path)\n",
    "    # grayscale_cam1 = Image.fromarray(grayscale_cam[:,:,np.newaxis])\n",
    "    # grayscale_cam1.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
